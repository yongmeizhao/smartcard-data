{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee300ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv #np.linalg.inv()：矩阵求逆\n",
    "import tensorly as tl\n",
    "import time\n",
    "import scipy.io\n",
    "import os\n",
    "import re\n",
    "from openpyxl import Workbook\n",
    "import scipy.io as sio\n",
    "\n",
    "def ten2mat(tensor, mode):#numpy.moveaxis(a, source, destination) a是数组，是原始位置，目标位置\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F') #张量展开\n",
    "\n",
    "def mat2ten(mat, tensor_size, mode):#张量折叠\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(tensor_size.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(tensor_size[index]), order = 'F'), 0, mode)\n",
    "# 包括任何输入矩阵 X，截断核规范（TNN）正则化的权重 α，学习率 ρ和正整数 θ 用于核规范的截断\n",
    "def compute_rmse(var, var_hat):\n",
    "    return np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])\n",
    "\n",
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_mae(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat)) / var.shape[0]\n",
    "\n",
    "from scipy import fftpack\n",
    "def svt_tnn(mat, tau, theta):\n",
    "    [m, n] = mat.shape\n",
    "    if 2 * m < n:\n",
    "        u, s, v = np.linalg.svd(mat @ mat.T, full_matrices = 0)\n",
    "        s = np.sqrt(s)\n",
    "        idx = np.sum(s > tau)\n",
    "        mid = np.zeros(idx)\n",
    "        mid[: theta] = 1\n",
    "        mid[theta : idx] = (s[theta : idx] - tau) / s[theta : idx]\n",
    "        return (u[:, : idx] @ np.diag(mid)) @ (u[:, : idx].T @ mat)\n",
    "def tSVST(X, beta,k,thfull=False):\n",
    "    n1, n2, n3 = X.shape\n",
    "    Xbar = np.fft.fft(X, axis=k)\n",
    "    Wbar = np.zeros((n1, n2, n3), dtype=complex)\n",
    "    if k == 0:\n",
    "        theta = int(np.ceil(0.05 * min(n3, n2)))  # 0.05\n",
    "        for i in range(0, int(np.ceil((n1 + 1) / 2))):\n",
    "            Wbar[i, :, :] = svt(Xbar[i, :, :], beta, theta)\n",
    "        for i in range(int(np.ceil((n1 + 1) / 2)), n1):\n",
    "            Wbar[i, :, :] = np.conj(Wbar[n1 - i, :, :])\n",
    "    elif k == 1:\n",
    "        theta = int(np.ceil(0.05* min(n1, n3)))\n",
    "        for i in range(0, int(np.ceil((n2 + 1) / 2))):\n",
    "            Wbar[:, i, :] = svt(Xbar[:, i, :], beta, theta)\n",
    "        for i in range(int(np.ceil((n2 + 1) / 2)), n2):\n",
    "            Wbar[:, i, :] = np.conj(Wbar[:, n2 - i, :])\n",
    "    elif k == 2:\n",
    "        theta = int(np.ceil(0.05 * min(n1, n2)))\n",
    "        for i in range(0, int(np.ceil((n3 + 1) / 2))):\n",
    "            Wbar[:, :, i] = svt(Xbar[:, :, i], beta, theta)\n",
    "        for i in range(int(np.ceil((n3 + 1) / 2)), n3):\n",
    "            Wbar[:, :, i] = np.conj(Wbar[:, :, n3 - i])\n",
    "    return np.real(np.fft.ifft(Wbar, axis=k))\n",
    "def BM(missing_rate):\n",
    "    dense_tensor = scipy.io.loadmat('tensor.mat')['tensor']\n",
    "    dim1, dim2, dim3 = dense_tensor.shape\n",
    "    print(\"dense_tensor.shape:\",dense_tensor.shape)\n",
    "    dim_time = dim2 * dim3\n",
    "    block_window = 6\n",
    "    vec = np.random.rand(int(dim_time / block_window))\n",
    "    temp = np.array([vec] * block_window)\n",
    "    vec = temp.reshape([dim2 * dim3], order='F')\n",
    "\n",
    "    sparse_tensor = mat2ten(ten2mat(dense_tensor, 0) * np.round(vec + 0.5 - missing_rate)[None, :],\n",
    "                            np.array([dim1, dim2, dim3]), 0)\n",
    "    sparse_tensor=sparse_tensor.transpose(0, 2, 1)\n",
    "    return sparse_tensor\n",
    "\n",
    "def RM(missing_rate):\n",
    "    sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "    return sparse_tensor\n",
    "\n",
    "\n",
    "def NM(missing_rate):\n",
    "\n",
    "# =============================================================================\n",
    "### Non-random missing (NM) scenario:\n",
    "  random_matrix = scipy.io.loadmat('random_matrix.mat')\n",
    "  random_matrix = random_matrix['random_matrix']\n",
    "  dense_tensor = scipy.io.loadmat('tensor.mat')['tensor']\n",
    "  binary_tensor = np.zeros(dense_tensor.shape)\n",
    "  for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "# =============================================================================\n",
    "  sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "  sparse_tensor = sparse_tensor.transpose(0, 2, 1)\n",
    "  return sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5961dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svt(mat, tau,theta,P=4.12):\n",
    "    [m, n] = mat.shape\n",
    "    if m > 2 * n:\n",
    "        return svt(mat.T,tau, theta).T\n",
    "    u, s, v = np.linalg.svd(mat, full_matrices = 0)\n",
    "    #tau = tau**(P-1)\n",
    "    idx = np.sum(0.5*s**((P-2)/2)>tau)\n",
    "    #print(\"idx=\",idx)\n",
    "    vec = s[:idx].copy()\n",
    "    vec[theta:] = np.maximum(vec[theta:] - tau , 0.0)\n",
    "    #print(\"打印出小于0的数的个数：\", np.sum((u[:,:idx] @ np.diag(vec) @ v[:idx,:])< 0))\n",
    "    return u[:,:idx] @ np.diag(vec) @ v[:idx,:]#输出一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d582990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRTC(dense_tensor, sparse_tensor, alpha, rho, epsilon, maxiter,theta):\n",
    "    \"\"\"Low-Rank Tenor Completion with Truncated Nuclear Norm, LRTC-TNN.\"\"\"\n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    pos_missing = np.where(sparse_tensor == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    X = np.zeros(np.insert(dim, 0, len(dim)))  # \\boldsymbol{\\mathcal{X}}\n",
    "    X1=np.zeros(np.insert(dim, 0, len(dim)))\n",
    "    T = np.zeros(np.insert(dim, 0, len(dim)))  # \\boldsymbol{\\mathcal{T}}\n",
    "    #print(\"打印出小于0的数的个数：\", np.sum(T < 0))\n",
    "    Z = sparse_tensor.copy()\n",
    "    Z1=sparse_tensor.copy()\n",
    "    print(\"Z1出小于0的数的个数：\", np.sum(Z1 < 0))\n",
    "    last_tensor = sparse_tensor.copy()\n",
    "    snorm = np.sqrt(np.sum(sparse_tensor **2))\n",
    "    it = 0\n",
    "    while True:\n",
    "        X1=X.copy()\n",
    "        Z1=Z.copy()\n",
    "        rho = min(rho * 1.2, 1e4)\n",
    "        '''\n",
    "        for k in range(dim0):\n",
    "            Z[:, :, :, k] = tSVST((tensor_hat + T[:, :, :, k] / rho),alpha[k] / rho,theta,k)\n",
    "        tensor_hat[pos_missing] = np.mean(Z - T / rho, axis=3)[pos_missing]\n",
    "        for k in range(dim0):\n",
    "            T[:, :, :, k] = T[:, :, :, k] + rho * (tensor_hat - Z[:, :, :, k])\n",
    "        tol = np.sqrt(np.sum((tensor_hat - last_tensor) ** 2)) / snorm\n",
    "        '''\n",
    "\n",
    "        for k in range(len(dim)):\n",
    "            X[k] = tSVST(Z, alpha[k]/rho, k)\n",
    "        Z[pos_missing] = np.mean(X + T / rho, axis=0)[pos_missing]\n",
    "        n= np.where(X <0)\n",
    "        X[n] = X1[n]\n",
    "        #print(\"X1小于0的数的个数：\", np.sum(X1 < 0))\n",
    "        #X=abs(X)\n",
    "        #T = T + rho * (X - np.broadcast_to(Z, np.insert(dim, 0, len(dim))))\n",
    "\n",
    "        tensor_hat = np.einsum('k, kmnt -> mnt', alpha, X)\n",
    "        tol = np.sqrt(np.sum((tensor_hat - last_tensor) ** 2)) / snorm\n",
    "        last_tensor = tensor_hat.copy()\n",
    "        it += 1\n",
    "        if (it + 1) % 10 == 0:\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "            #print(int(np.ceil(theta * dim[k])))\n",
    "            print()\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "\n",
    "        #Z = abs(Z)\n",
    "        n=np.where(Z<0)\n",
    "        Z[n]=Z1[n]\n",
    "        #Z1 = abs(Z)\n",
    "        #print(\"Z1出小于0的数的个数：\", np.sum(Z1<0))\n",
    "\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test])))\n",
    "    return tensor_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9577737b",
   "metadata": {},
   "source": [
    "多源测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6a6af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 329)\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 3.48352\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 3.07397\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 3.08186\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 3.14688\n",
      "\n",
      "Imputation MAPE: 0.575964\n",
      "Imputation RMSE: 3.15337\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 3.97453\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 3.25216\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 3.12333\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 3.17736\n",
      "\n",
      "Imputation MAPE: 0.56371\n",
      "Imputation RMSE: 3.18299\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 3.96313\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 3.25238\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 3.10885\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 3.16048\n",
      "\n",
      "Imputation MAPE: 0.578145\n",
      "Imputation RMSE: 3.16728\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 4.19281\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 3.37627\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 3.13356\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 3.1864\n",
      "\n",
      "Imputation MAPE: 0.582528\n",
      "Imputation RMSE: 3.19427\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 4.51633\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 3.46155\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 3.19942\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 3.24911\n",
      "\n",
      "Imputation MAPE: 0.584675\n",
      "Imputation RMSE: 3.2577\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 5.01911\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 3.82822\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 3.40527\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 3.43782\n",
      "\n",
      "Imputation MAPE: 0.604551\n",
      "Imputation RMSE: 3.445\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 6.11804\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 4.40402\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 3.774\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 3.77415\n",
      "\n",
      "Imputation MAPE: 0.599597\n",
      "Imputation RMSE: 3.77735\n",
      "(1, 288, 329)\n",
      "Z1出小于0的数的个数： 0\n",
      "Iter: 10\n",
      "RMSE: 7.71505\n",
      "\n",
      "Iter: 20\n",
      "RMSE: 6.00482\n",
      "\n",
      "Iter: 30\n",
      "RMSE: 5.1099\n",
      "\n",
      "Iter: 40\n",
      "RMSE: 5.06928\n",
      "\n",
      "Iter: 50\n",
      "RMSE: 5.06655\n",
      "\n",
      "Imputation MAPE: 0.579524\n",
      "Imputation RMSE: 5.06647\n"
     ]
    }
   ],
   "source": [
    "#读取数据\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pl\n",
    "\n",
    "\n",
    "tensorone = scipy.io.loadmat('506.mat')\n",
    "dense_one = tensorone['tensor']\n",
    "print(dense_one.shape)\n",
    "\n",
    "start = time.time()\n",
    "alpha = np.ones(3) / 3\n",
    "\n",
    "maxiter = 150\n",
    "\n",
    "#对每一行乘一个偏置值\n",
    "#bais = np.round(np.random.rand(dim[0], dim[1])[:, :, np.newaxis] + 0.5 - missing_rate)\n",
    "#sparse_tensor = dense_tensor * bais\n",
    "#维度变化，dim[0]为1\n",
    "\n",
    "#sparse_mat = sparse_tensor.reshape([dim[0]*dim[1] , dim[2]])\n",
    "#dense_mat = dense_mat[0:dim[1], dim[2]] #取全部数据\n",
    "#sparse_mat = sparse_mat[0:dim[1], dim[2]]\n",
    "\n",
    "workbook = Workbook()\n",
    "booksheet = workbook.active\n",
    "booksheet.append(['缺失率', 'RM', 'NM', 'BM'])\n",
    "missing_rate=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "listrmse=[]\n",
    "for i in range(0, len(missing_rate)):\n",
    "\n",
    "    listRow = []\n",
    "    listrmseR=[]\n",
    "    listRow.append(missing_rate[i])\n",
    "    listmaeR = []\n",
    "    listmaeR.append(\" \")\n",
    "    listrmseR.append(\" \")\n",
    "    dense_list=[]\n",
    "    dense_list.append(dense_one)\n",
    "    dense_tensor=np.array(dense_list)\n",
    "    print(dense_tensor.shape)\n",
    "    dim =np.shape(dense_tensor)\n",
    "    sparse_list=[]\n",
    "    sparse_tensor = RM(missing_rate[i])\n",
    "    sparse_mat = sparse_tensor.reshape([dim[0]*dim[1] , dim[2]])\n",
    "    sparse_mat1=np.array(sparse_mat)\n",
    "    sparse_list.append(sparse_mat1)\n",
    "    tensortwo = scipy.io.loadmat('506bus.mat')\n",
    "    dense_two = tensortwo['tensor']\n",
    "    dense_list.append(dense_two)\n",
    "    sparse_list.append(dense_two)\n",
    "    dense_tensor=np.array(dense_list)\n",
    "    sparse_tensor=np.array(sparse_list)\n",
    "    dim =np.shape(dense_tensor)\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    pos_missing = np.where(sparse_tensor == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    rho = 1e-4# 非随机设置为1e-5，随机设置为1e-4，迭代次数更少,sz数据需设置为1e-6\n",
    "    epsilon = 1e-3 # 非随机设置为1e-4，随机设置为1e-3，迭代次数更少,sz数据需设置为1e-5\n",
    "    tensor_hat=LRTC(dense_tensor, sparse_tensor, alpha, rho, epsilon, maxiter,theta=20)\n",
    "    listRow.append(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "    listrmseR.append(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "    listmaeR.append(compute_mae(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "    '''\n",
    "    sparse_tensor = NM(missing_rate[i])\n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    pos_missing = np.where(sparse_tensor == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    rho = 1e-5  # 非随机设置为1e-5，随机设置为1e-4，迭代次数更少\n",
    "    epsilon = 1e-4  # 非随机设置为1e-4，随机设置为1e-3，迭代次数更少\n",
    "    tensor_hat = LRTC(dense_tensor, sparse_tensor, alpha, rho, epsilon, maxiter,theta=30)\n",
    "    listRow.append(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "    listrmseR.append(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "    listmaeR.append(compute_mae(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "\n",
    "    sparse_tensor = BM(missing_rate[i])\n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    pos_missing = np.where(sparse_tensor == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    rho = 1e-5  # 非随机设置为1e-5，随机设置为1e-4，迭代次数更少\n",
    "    epsilon = 1e-4  # 非随机设置为1e-4，随机设置为1e-3，迭代次数更少\n",
    "    tensor_hat = LRTC(dense_tensor, sparse_tensor, alpha, rho, epsilon, maxiter,theta=30)\n",
    "    listRow.append(compute_mape(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "    listrmseR.append(compute_rmse(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "    listmaeR.append(compute_mae(dense_tensor[pos_test], tensor_hat[pos_test]))\n",
    "'''\n",
    "    booksheet.append(listRow)\n",
    "    booksheet.append(listrmseR)\n",
    "    booksheet.append(listmaeR)\n",
    "workbook.save(\"sz1运行结果.xls\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
